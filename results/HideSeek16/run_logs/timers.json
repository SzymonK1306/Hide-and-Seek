{
    "name": "root",
    "gauges": {
        "SeekerBehavior.Policy.Entropy.mean": {
            "value": 1.6196671724319458,
            "min": 1.5195480585098267,
            "max": 1.6196671724319458,
            "count": 54
        },
        "SeekerBehavior.Policy.Entropy.sum": {
            "value": 242912.828125,
            "min": 19795.15234375,
            "max": 242912.828125,
            "count": 54
        },
        "SeekerBehavior.Step.mean": {
            "value": 27299991.0,
            "min": 19349970.0,
            "max": 27299991.0,
            "count": 54
        },
        "SeekerBehavior.Step.sum": {
            "value": 27299991.0,
            "min": 19349970.0,
            "max": 27299991.0,
            "count": 54
        },
        "SeekerBehavior.Policy.ExtrinsicValueEstimate.mean": {
            "value": 4.106791019439697,
            "min": 4.106791019439697,
            "max": 23.243331909179688,
            "count": 54
        },
        "SeekerBehavior.Policy.ExtrinsicValueEstimate.sum": {
            "value": 10763.8994140625,
            "min": 4950.82958984375,
            "max": 53735.96875,
            "count": 54
        },
        "SeekerBehavior.Environment.EpisodeLength.mean": {
            "value": 394.6062992125984,
            "min": 322.7037037037037,
            "max": 397.71276595744683,
            "count": 54
        },
        "SeekerBehavior.Environment.EpisodeLength.sum": {
            "value": 150345.0,
            "min": 8713.0,
            "max": 151651.0,
            "count": 54
        },
        "SeekerBehavior.Environment.CumulativeReward.mean": {
            "value": -78.00890007521224,
            "min": -79.90254226334805,
            "max": 85.87654928807859,
            "count": 54
        },
        "SeekerBehavior.Environment.CumulativeReward.sum": {
            "value": -29721.390928655863,
            "min": -30283.063517808914,
            "max": 33223.523050278425,
            "count": 54
        },
        "SeekerBehavior.Policy.ExtrinsicReward.mean": {
            "value": -78.00890007521224,
            "min": -79.90254226334805,
            "max": 85.87654928807859,
            "count": 54
        },
        "SeekerBehavior.Policy.ExtrinsicReward.sum": {
            "value": -29721.390928655863,
            "min": -30283.063517808914,
            "max": 33223.523050278425,
            "count": 54
        },
        "SeekerBehavior.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 54
        },
        "SeekerBehavior.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 54
        },
        "HiderBehavior.Policy.Entropy.mean": {
            "value": 1.4844660758972168,
            "min": 1.4844659566879272,
            "max": 1.6032334566116333,
            "count": 167
        },
        "HiderBehavior.Policy.Entropy.sum": {
            "value": 222634.28125,
            "min": 193485.78125,
            "max": 241311.515625,
            "count": 167
        },
        "HiderBehavior.Step.mean": {
            "value": 83399990.0,
            "min": 58499980.0,
            "max": 83399990.0,
            "count": 167
        },
        "HiderBehavior.Step.sum": {
            "value": 83399990.0,
            "min": 58499980.0,
            "max": 83399990.0,
            "count": 167
        },
        "HiderBehavior.Policy.ExtrinsicBaselineEstimate.mean": {
            "value": 34.37607955932617,
            "min": 8.567243576049805,
            "max": 35.44600296020508,
            "count": 167
        },
        "HiderBehavior.Policy.ExtrinsicBaselineEstimate.sum": {
            "value": 82880.7265625,
            "min": 19878.046875,
            "max": 85460.3125,
            "count": 167
        },
        "HiderBehavior.Policy.ExtrinsicValueEstimate.mean": {
            "value": 34.90395736694336,
            "min": 6.398327350616455,
            "max": 36.1782341003418,
            "count": 167
        },
        "HiderBehavior.Policy.ExtrinsicValueEstimate.sum": {
            "value": 84153.4375,
            "min": 14994.8544921875,
            "max": 87225.71875,
            "count": 167
        },
        "HiderBehavior.Environment.EpisodeLength.mean": {
            "value": 476.59485530546624,
            "min": 308.2853107344633,
            "max": 481.52884615384613,
            "count": 167
        },
        "HiderBehavior.Environment.EpisodeLength.sum": {
            "value": 148221.0,
            "min": 109133.0,
            "max": 156097.0,
            "count": 167
        },
        "HiderBehavior.Environment.CumulativeReward.mean": {
            "value": 3.3265248640557195,
            "min": 3.1798360292462333,
            "max": 4.84051277917341,
            "count": 167
        },
        "HiderBehavior.Environment.CumulativeReward.sum": {
            "value": 1034.5492327213287,
            "min": 989.3546732068062,
            "max": 2298.883613437414,
            "count": 167
        },
        "HiderBehavior.Policy.ExtrinsicReward.mean": {
            "value": 127.86401259707485,
            "min": -12.293772911494809,
            "max": 133.28029427238,
            "count": 167
        },
        "HiderBehavior.Policy.ExtrinsicReward.sum": {
            "value": 39765.70791769028,
            "min": -5937.892316251993,
            "max": 42389.61905449629,
            "count": 167
        },
        "HiderBehavior.Environment.GroupCumulativeReward.mean": {
            "value": 133.45195729537366,
            "min": -12.937062937062937,
            "max": 137.2852233676976,
            "count": 167
        },
        "HiderBehavior.Environment.GroupCumulativeReward.sum": {
            "value": 37500.0,
            "min": -2550.0,
            "max": 39950.0,
            "count": 167
        },
        "HiderBehavior.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 167
        },
        "HiderBehavior.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 167
        },
        "HiderBehavior.Losses.PolicyLoss.mean": {
            "value": 0.021615638238613934,
            "min": 0.021615638238613934,
            "max": 0.030166251633717264,
            "count": 27
        },
        "HiderBehavior.Losses.PolicyLoss.sum": {
            "value": 0.021615638238613934,
            "min": 0.021615638238613934,
            "max": 0.030166251633717264,
            "count": 27
        },
        "HiderBehavior.Losses.ValueLoss.mean": {
            "value": 192.79535624186198,
            "min": 87.61966576046414,
            "max": 195.79571601019964,
            "count": 27
        },
        "HiderBehavior.Losses.ValueLoss.sum": {
            "value": 192.79535624186198,
            "min": 87.61966576046414,
            "max": 195.79571601019964,
            "count": 27
        },
        "HiderBehavior.Losses.BaselineLoss.mean": {
            "value": 207.21930872599285,
            "min": 119.84601512485081,
            "max": 220.02985026041668,
            "count": 27
        },
        "HiderBehavior.Losses.BaselineLoss.sum": {
            "value": 207.21930872599285,
            "min": 119.84601512485081,
            "max": 220.02985026041668,
            "count": 27
        },
        "HiderBehavior.Policy.LearningRate.mean": {
            "value": 0.0002950266210977935,
            "min": 0.0002950266210977935,
            "max": 0.0002964444537451824,
            "count": 27
        },
        "HiderBehavior.Policy.LearningRate.sum": {
            "value": 0.0002950266210977935,
            "min": 0.0002950266210977935,
            "max": 0.0002964444537451824,
            "count": 27
        },
        "HiderBehavior.Policy.Epsilon.mean": {
            "value": 0.19834220648,
            "min": 0.19834220648,
            "max": 0.19881481751999996,
            "count": 27
        },
        "HiderBehavior.Policy.Epsilon.sum": {
            "value": 0.19834220648,
            "min": 0.19834220648,
            "max": 0.19881481751999996,
            "count": 27
        },
        "HiderBehavior.Policy.Beta.mean": {
            "value": 0.009834386427352002,
            "min": 0.009834386427352002,
            "max": 0.009881600270247998,
            "count": 27
        },
        "HiderBehavior.Policy.Beta.sum": {
            "value": 0.009834386427352002,
            "min": 0.009834386427352002,
            "max": 0.009881600270247998,
            "count": 27
        },
        "SeekerBehavior.Losses.PolicyLoss.mean": {
            "value": 0.019266542803395875,
            "min": 0.018464370262679747,
            "max": 0.023981258506844624,
            "count": 18
        },
        "SeekerBehavior.Losses.PolicyLoss.sum": {
            "value": 0.019266542803395875,
            "min": 0.018464370262679747,
            "max": 0.023981258506844624,
            "count": 18
        },
        "SeekerBehavior.Losses.ValueLoss.mean": {
            "value": 350.6383951822917,
            "min": 192.72552575005426,
            "max": 350.6383951822917,
            "count": 18
        },
        "SeekerBehavior.Losses.ValueLoss.sum": {
            "value": 350.6383951822917,
            "min": 192.72552575005426,
            "max": 350.6383951822917,
            "count": 18
        },
        "SeekerBehavior.Policy.LearningRate.mean": {
            "value": 0.00029837609046130337,
            "min": 0.00029837609046130337,
            "max": 0.0002988140268953245,
            "count": 18
        },
        "SeekerBehavior.Policy.LearningRate.sum": {
            "value": 0.00029837609046130337,
            "min": 0.00029837609046130337,
            "max": 0.0002988140268953245,
            "count": 18
        },
        "SeekerBehavior.Policy.Epsilon.mean": {
            "value": 0.19945869664000004,
            "min": 0.19945869664000004,
            "max": 0.19960467550000008,
            "count": 18
        },
        "SeekerBehavior.Policy.Epsilon.sum": {
            "value": 0.19945869664000004,
            "min": 0.19945869664000004,
            "max": 0.19960467550000008,
            "count": 18
        },
        "SeekerBehavior.Policy.Beta.mean": {
            "value": 0.009945923794335999,
            "min": 0.009945923794335999,
            "max": 0.00996050708245,
            "count": 18
        },
        "SeekerBehavior.Policy.Beta.sum": {
            "value": 0.009945923794335999,
            "min": 0.009945923794335999,
            "max": 0.00996050708245,
            "count": 18
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1699663728",
        "python_version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "D:\\Programs\\Unity\\Projects\\Engineering\\venv\\Scripts\\mlagents-learn results/HideSeek16/configuration.yaml --run-id=HideSeek16 --resume --torch-device=cuda",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.0.1+cu117",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1699698938"
    },
    "total": 35209.6190868,
    "count": 1,
    "self": 0.02070090000052005,
    "children": {
        "run_training.setup": {
            "total": 0.12993849999999973,
            "count": 1,
            "self": 0.12993849999999973
        },
        "TrainerController.start_learning": {
            "total": 35209.468447399995,
            "count": 1,
            "self": 11.417485399841098,
            "children": {
                "TrainerController._reset_env": {
                    "total": 14.9010636,
                    "count": 1,
                    "self": 14.9010636
                },
                "TrainerController.advance": {
                    "total": 35182.27040070016,
                    "count": 463539,
                    "self": 12.865074600238586,
                    "children": {
                        "env_step": {
                            "total": 13418.519301300028,
                            "count": 463539,
                            "self": 10078.352444699682,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 3334.6993465012188,
                                    "count": 463539,
                                    "self": 202.81130040185099,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 3131.888046099368,
                                            "count": 845361,
                                            "self": 3131.888046099368
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 5.467510099127054,
                                    "count": 463539,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 35187.99129359902,
                                            "count": 463539,
                                            "is_parallel": true,
                                            "self": 27844.36266439832,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00717670000000048,
                                                    "count": 2,
                                                    "is_parallel": true,
                                                    "self": 0.00040619999999869094,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.006770500000001789,
                                                            "count": 8,
                                                            "is_parallel": true,
                                                            "self": 0.006770500000001789
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 7343.621452500702,
                                                    "count": 463539,
                                                    "is_parallel": true,
                                                    "self": 238.2188577015968,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 342.86687689933484,
                                                            "count": 463539,
                                                            "is_parallel": true,
                                                            "self": 342.86687689933484
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 6215.860198700902,
                                                            "count": 463539,
                                                            "is_parallel": true,
                                                            "self": 6215.860198700902
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 546.6755191988673,
                                                            "count": 927078,
                                                            "is_parallel": true,
                                                            "self": 103.46761759712626,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 443.207901601741,
                                                                    "count": 3708312,
                                                                    "is_parallel": true,
                                                                    "self": 443.207901601741
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 21750.88602479989,
                            "count": 927078,
                            "self": 41.98783069955243,
                            "children": {
                                "process_trajectory": {
                                    "total": 12366.477890800339,
                                    "count": 927078,
                                    "self": 12342.365363700343,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 24.11252709999721,
                                            "count": 67,
                                            "self": 24.11252709999721
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 9342.4203033,
                                    "count": 45,
                                    "self": 2950.8722200999327,
                                    "children": {
                                        "TorchPOCAOptimizer.update": {
                                            "total": 5846.363926700064,
                                            "count": 4860,
                                            "self": 5846.363926700064
                                        },
                                        "TorchPPOOptimizer.update": {
                                            "total": 545.1841565000018,
                                            "count": 1620,
                                            "self": 545.1841565000018
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 3.5999983083456755e-06,
                    "count": 1,
                    "self": 3.5999983083456755e-06
                },
                "TrainerController._save_models": {
                    "total": 0.87949409999419,
                    "count": 1,
                    "self": 0.12601169999834383,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.7534823999958462,
                            "count": 2,
                            "self": 0.7534823999958462
                        }
                    }
                }
            }
        }
    }
}